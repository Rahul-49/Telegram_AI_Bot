{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "id": "c6324cfa",
        "outputId": "6282ada8-f9e4-462a-f7dd-d547c017326f"
      },
      "source": [
        "pip install python-telegram-bot==13.15"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot==13.15\n",
            "  Downloading python_telegram_bot-13.15-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot==13.15) (2025.4.26)\n",
            "Collecting tornado==6.1 (from python-telegram-bot==13.15)\n",
            "  Downloading tornado-6.1.tar.gz (497 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m497.4/497.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.15)\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot==13.15) (2025.2)\n",
            "Collecting cachetools==4.2.2 (from python-telegram-bot==13.15)\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.11/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15) (1.17.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.11/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15) (5.3.1)\n",
            "Downloading python_telegram_bot-13.15-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: tornado\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.1-cp311-cp311-linux_x86_64.whl size=422006 sha256=34655acda7ae1d0cf36ad147fbee2086bcb48c4afbe485f475476ea6c3d32e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/59/06/a9c85c7b17ec0fc9b1e2ae0c59e3d39255d5c0a38492e33fea\n",
            "Successfully built tornado\n",
            "Installing collected packages: tornado, cachetools, APScheduler, python-telegram-bot\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.4.2\n",
            "    Uninstalling tornado-6.4.2:\n",
            "      Successfully uninstalled tornado-6.4.2\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: python-telegram-bot\n",
            "    Found existing installation: python-telegram-bot 22.1\n",
            "    Uninstalling python-telegram-bot-22.1:\n",
            "      Successfully uninstalled python-telegram-bot-22.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.1 which is incompatible.\n",
            "bokeh 3.7.3 requires tornado>=6.2; sys_platform != \"emscripten\", but you have tornado 6.1 which is incompatible.\n",
            "distributed 2024.12.1 requires tornado>=6.2.0, but you have tornado 6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.15 tornado-6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cachetools",
                  "telegram",
                  "tornado"
                ]
              },
              "id": "37f5b8e2118f4bf4938c4b610c3327c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from telegram import Update\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, CallbackContext\n",
        "from telegram.ext.filters import Filters\n",
        "from google import genai\n",
        "import os\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyCp6IAWRepOOLnMj_IPBqag_mcaLCZZ4qI\")\n",
        "\n",
        "def generate_ai_response(user_input):\n",
        "    try:\n",
        "        model = \"gemini-2.0-flash\"\n",
        "        contents = [\n",
        "            types.Content(role=\"user\", parts=[types.Part.from_text(text=user_input)])\n",
        "        ]\n",
        "\n",
        "        generate_content_config = types.GenerateContentConfig(\n",
        "            temperature=0.5,\n",
        "            max_output_tokens=4096,\n",
        "            response_mime_type=\"text/plain\",\n",
        "            system_instruction=[\n",
        "                types.Part.from_text(text=\"You're a smart, playful AI assistant who adapts to the user's intent and tone. \"\n",
        "                \"Use emojis occasionally (not excessively) to add flavor ðŸ¤–âœ¨. \"\n",
        "                \"Respond only in clean, plain text\"\n",
        "                \"A little concise\"\n",
        "                \"You speak like a university student â€” casual, clear, and relatable â€” especially when explaining concepts. \"\n",
        "                \"Be a bit sarcastic and cheeky, but only where it fits (not when explaining important subjects). \"\n",
        "                \"Above all, make sure your replies match what the user wants â€” mirror their mood, style, and intent.\")\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        response_text = \"\"\n",
        "        for chunk in client.models.generate_content_stream(model=model, contents=contents, config=generate_content_config):\n",
        "            response_text += chunk.text  # Collecting streamed response\n",
        "\n",
        "        return response_text if response_text else \"âš ï¸ Oops! I couldn't generate a response. Try again! ðŸ˜…\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "\n",
        "# Telegram API\n",
        "TOKEN = \"7185027692:AAHiuQ3shtdQbqghRSnG9PgCNs5HQiZhHmw\"\n",
        "\n",
        "# Function to handle the /start command\n",
        "def start(update: Update, context: CallbackContext) -> None:\n",
        "    update.message.reply_text(\"Hello! I am your bot. Send me a message.\")\n",
        "\n",
        "# Function to handle user messages\n",
        "def handle_message(update: Update, context: CallbackContext) -> None:\n",
        "    user_message = update.message.text  # <-- User message is captured here\n",
        "    response = generate_ai_response(user_message)\n",
        "    update.message.reply_text(response)\n",
        "\n",
        "def help_command(update: Update, context: CallbackContext) -> None:\n",
        "    help_text = (\n",
        "        \"Here are the commands you can use:\\n\"\n",
        "        \"/start - Start the bot and receive a welcome message.\\n\"\n",
        "        \"/help - Display this help message.\\n\"\n",
        "        \"You can also send me any text message, and I'll respond accordingly.\"\n",
        "    )\n",
        "    update.message.reply_text(help_text)\n",
        "# Function to set up the bot\n",
        "def main():\n",
        "    updater = Updater(TOKEN, use_context=True)\n",
        "    dp = updater.dispatcher\n",
        "\n",
        "    # Add command handlers\n",
        "    dp.add_handler(CommandHandler(\"start\", start))\n",
        "    dp.add_handler(CommandHandler(\"help\", help_command))  # Register the help command handler\n",
        "    dp.add_handler(MessageHandler(Filters.text & ~Filters.command, handle_message))\n",
        "\n",
        "    # Start the bot\n",
        "    updater.start_polling()\n",
        "    updater.idle()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "kgCjQBkEfV27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVnYcSmaiGec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}